# Offensive-Language-Identification-Project

In this project, we tried to utilize models which are capable of analyzing tweets and concluding
whether the tweets are offensive or not. Also, if the tweets are offensive,
the model can also decide whether the offense was targeted or
not. Here, we used a public dataset available online, called the Offensive
Language Identification Dataset (OLID). We used two types of
Recurrent Neural Network (RNN) Models to do our task, which include
both Unidirectional and Bidirectional Long Short-Term Memory
(LSTM) and Bidirectional Gated Recurrent Unit (GRU). The accuracy,
precision, recall, F1 and F2 scores of our models are discussed
in this report, along with the process in which these models work.
